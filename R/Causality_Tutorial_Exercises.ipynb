{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaQIJ9pj4Rqv"
   },
   "source": [
    "# Causality Tutorial Exercises â€“ R\n",
    "\n",
    "Contributors: Rune Christiansen, Jonas Peters, Niklas Pfister, Sorawit Saengkyongam, Sebastian Weichwald.\n",
    "The MIT License applies; copyright is with the authors.\n",
    "Some exercises are adapted from \"Elements of Causal Inference: Foundations and Learning Algorithms\" by J. Peters, D. Janzing and B. SchÃ¶lkopf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bobON40QU5hk"
   },
   "source": [
    "# Exercise 1 â€“ Structural Causal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qhShyZbusKxG"
   },
   "source": [
    "Let's first draw a sample from an SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAD0hTOf9Sh1"
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "n <- 200\n",
    "C <- rnorm(n)\n",
    "A <- 0.8*rnorm(n)\n",
    "K <- A + 0.1*rnorm(n)\n",
    "X <- C - 2*A + 0.2*rnorm(n)\n",
    "F <- 3*X + 0.8*rnorm(n)\n",
    "D <- -2*X + 0.5*rnorm(n)\n",
    "G <- D + 0.5*rnorm(n)\n",
    "Y <- 2*K - D + 0.2*rnorm(n)\n",
    "H <- 0.5*Y + 0.1*rnorm(n)\n",
    "\n",
    "data.obs <- cbind(C, A, K, X, F, D, G, Y, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "\n",
    "What are the parents and children of $X$ in the above SCM ?\n",
    "\n",
    "Take a pair of variables and think about whether you expect this pair to be dependent\n",
    "(at this stage, you can only guess, later you will have tools to know). Check empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PMvvEeIoKFN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "\n",
    "Generate a sample of size 300 from the interventional distribution $P_{\\mathrm{do}(X=\\mathcal{N}(2, 1))}$\n",
    "and store the data matrix as `data.int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bokBGvsmVCQJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3wOg_4vozpz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "\n",
    "Do you expect the marginal distribution of $Y$ to be different in both samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3paV1bkro6lV"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH9Tt444o-RH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d)\n",
    "\n",
    "Do you expect the joint distribution of $(A, Y)$ to be different in both samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJz4fZKEpE4-"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZmh_AizpGp-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (e)\n",
    "\n",
    "Check your answers to c) and d) empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMiVnsjeVC2-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjECw2eiVFjC"
   },
   "source": [
    "# Exercise 2 â€“ Adjusting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il0b9fnVq-bz"
   },
   "source": [
    "\n",
    "![DAG](https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.png)\n",
    "\n",
    "Suppose we are given a fixed DAG (like the one above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "What are valid adjustment sets (VAS) used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "\n",
    "Assume we want to find a VAS for the causal effect from $X$ to $Y$.\n",
    "What are general recipies (plural ðŸ˜‰) for constructing VASs (no proof)?\n",
    "Which sets are VAS in the DAG above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "\n",
    "The following code samples from an SCM. Perform linear regressions using different VAS and compare the regression coefficient against the causal effect from $X$ to $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IaJjtEMUoO1I"
   },
   "outputs": [],
   "source": [
    "set.seed(1)\n",
    "\n",
    "n <- 200\n",
    "C <- rnorm(n)\n",
    "A <- 0.8*rnorm(n)\n",
    "K <- A + 1.1*rnorm(n)\n",
    "X <- C - 2*A + 0.2*rnorm(n)\n",
    "F <- 3*X + 0.8*rnorm(n)\n",
    "D <- -2*X + 0.5*rnorm(n)\n",
    "G <- D + 0.5*rnorm(n)\n",
    "Y <- 2*K - D + 0.2*rnorm(n)\n",
    "H <- 0.5*Y + 0.1*rnorm(n)\n",
    "\n",
    "data.obs <- cbind(C, A, K, X, F, D, G, Y, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d)\n",
    "\n",
    "Why could it be interesting to have several options for choosing a VAS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC4_cF0XoQqN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (e)\n",
    "\n",
    "If you indeed have access to several VASs, what would you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ7RuuF4rMD6"
   },
   "source": [
    "# Exercise 3 â€“ Independence-based Causal Structure Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "\n",
    "Assume $P^{X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
    "\n",
    "$$\n",
    "\\newcommand{\\indep}{{\\,â««\\,}}\n",
    "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
    "$$\n",
    "\n",
    "$$X \\dep Z \\mid \\emptyset$$\n",
    "\n",
    "(plus symmetric statements). What is $G$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p21N9AFBrB0o"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "\n",
    "Assume $P^{W,X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
    "\n",
    "$$\\begin{aligned}\n",
    "(Y,Z) &\\indep W \\mid \\emptyset \\\\\n",
    "W &\\indep Y \\mid (X,Z) \\\\\n",
    "(X,W) &\\indep Y | Z\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "(plus symmetric statements). What is $G$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtBvbvkNWXSo"
   },
   "source": [
    "# Exercise 4 â€“ Additive Noise Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ONM6ulNwWpk"
   },
   "source": [
    "Set-up required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqnELcs_pI32"
   },
   "outputs": [],
   "source": [
    "# set up â€“ not needed when run on mybinder\n",
    "# if needed (colab), change FALSE to TRUE and run cell\n",
    "if (FALSE) {\n",
    "  install.packages('dHSIC')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcH5XTGNweBH"
   },
   "outputs": [],
   "source": [
    "library(mgcv)\n",
    "library(dHSIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXoqFwV0wiGT"
   },
   "source": [
    "Let's load and plot some real data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X10gfbouWe7z"
   },
   "outputs": [],
   "source": [
    "# Load some real data set\n",
    "real.dat <- read.csv('https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.csv')\n",
    "Y <- real.dat[, \"Y\"]\n",
    "X <- real.dat[, \"X\"]\n",
    "\n",
    "# Let us plot the data\n",
    "par(mfrow=c(1,1))\n",
    "plot(X, Y, pch = 19, cex = .8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV-Pvjsqx7Fz",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "\n",
    "Do you believed that $X \\to Y$ or that $X \\gets Y$? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUv9ROdOyCXB"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "\n",
    "$$\n",
    "\\newcommand{\\indep}{{\\,â««\\,}}\n",
    "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
    "$$\n",
    "\n",
    "Let us now try to get a more statistical answer. We have heard that we cannot \n",
    "have  \n",
    "$$Y = f(X) + N_Y,\\ N_Y \\indep X$$\n",
    "and\n",
    "$$X = g(Y) + N_X,\\ N_X \\indep Y$$\n",
    "at the same time.\n",
    "\n",
    "Given a data set over $(X,Y)$,\n",
    "we now want to decide for one of the two models. \n",
    "\n",
    "Come up with a method to do so.\n",
    "\n",
    "Hints: \n",
    "* `gam(B âˆ¼ s(A))$residuals` provides residuals when regressing $B$ on $A$. \n",
    "* `dhsic.test` (with `method = \"gamma\"`) can be used as an independence test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkvF9mjzW4tS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff7xkIzByx8X",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "\n",
    "Assume that the error terms are Gaussian with zero mean and variances \n",
    "$\\sigma_X^2$ and $\\sigma_Y^2$, respectively.\n",
    "The maximum likelihood for DAG G is \n",
    "then proportional to \n",
    "$-\\log(\\mathrm{var}(R^G_X)) - \\log(\\mathrm{var}(R^G_Y))$,\n",
    "where $R^G_X$ and $R^G_Y$ are the residuals obtained from regressing $X$ and $Y$ on \n",
    "their parents in $G$, respectively (no proof).\n",
    "\n",
    "Find the maximum likelihood solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUB-zlgwW6FS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPgnXJvlXAc4"
   },
   "source": [
    "# Exercise 5 â€“ Invariant Causal Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cuaTYbq09wN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "\n",
    "Generate some observational and interventional data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OPBqL5jXHqZ"
   },
   "outputs": [],
   "source": [
    "# Generate n=1000 observations from the observational distribution\n",
    "na <- 1000\n",
    "Xa <- rnorm(na)\n",
    "Ya <- 1.5*Xa + rnorm(na)\n",
    "\n",
    "# Generate n=1000 observations from an interventional distribution\n",
    "nb <- 1000\n",
    "Xb <- rnorm(nb, 2, 1)\n",
    "Yb <- 1.5*Xb + rnorm(nb)\n",
    "red <- rgb(1,0,0,alpha=0.4)\n",
    "blue <- rgb(0,0,1,alpha=0.4)\n",
    "\n",
    "# plot Y vs X1\n",
    "plot(Xa,Ya,pch=16,col=blue,xlim=range(c(Xa,Xb)),ylim=range(c(Ya,Yb)),xlab=\"X\",ylab=\"Y\")\n",
    "points(Xb,Yb,pch=17,col=red)\n",
    "legend(\"topright\",c(\"observational\",\"interventional\"),pch=c(16,17),col=c(blue,red),inset=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZcSibWjypDR"
   },
   "source": [
    "Look at the above plot. Is the predictor $\\{X\\}$ an invariant set, that is (roughly speaking), does $Y \\mid X = x$ have the same distribution in the red and blue data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhnmzEIiyvmt"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0PC0Vy01BNc",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "We now consider data over a response and three covariates $X1, X2$, and $X3$\n",
    "and try to infer $\\mathrm{pa}(Y)$. To do so, we need to find all sets for which this\n",
    "invariance is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Al8FBjpXXSDV"
   },
   "outputs": [],
   "source": [
    "data <- as.matrix(read.csv('https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ICP.csv'))\n",
    "pairs(data, col = c(rep(1,140), rep(2,80)))\n",
    "\n",
    "# The code below plots the residuals versus fitted values for all sets of \n",
    "# predictors. \n",
    "# extract response and predictors\n",
    "Y <- data[,1]\n",
    "Xmat  <- data[,2:4]\n",
    "S <- list( c(1), c(2), c(3), c(1,2), c(1,3), c(2,3), c(1,2,3))\n",
    "resid <- fitted <- vector(\"list\", length(S))\n",
    "for(i in 1:length(S)){\n",
    "  modelfit <- lm.fit(Xmat[,S[[i]],drop=FALSE], Y)\n",
    "  resid[[i]] <- modelfit$residuals\n",
    "  fitted[[i]] <- modelfit$fitted.values\n",
    "}\n",
    "env <- c(rep(0,140),rep(1,80))\n",
    "par(mfrow=c(2,2))\n",
    "red <- rgb(1,0,0,alpha=0.4)\n",
    "blue <- rgb(0,0,1,alpha=0.4)\n",
    "names <- c(\"X1\", \"X2\", \"X3\", \"X1, X2\", \"X1, X3\", \"X2, X3\", \"X1, X2, X3\")\n",
    "plot((1:length(Y))[env==0], Y[env==0], pch=16, col=blue, xlim=c(0,220), ylim=range(Y), xlab=\"index\", ylab=\"Y\", main=\"empty set\")\n",
    "points((1:length(Y))[env==1], Y[env==1], pch=17, col=red)\n",
    "legend(\"topleft\",c(\"observational\",\"interventional\"),pch=c(16,17),col=c(blue,red),inset=0.02)\n",
    "for(i in 1:length(S)){\n",
    "  plot(fitted[[i]][env==0], resid[[i]][env==0], pch=16, col=blue, xlim=range(fitted[[i]]), ylim=range(resid[[i]]), xlab=\"fitted values\", ylab=\"residuals\", main=names[i])\n",
    "  points(fitted[[i]][env==1], resid[[i]][env==1], pch=17, col=red)\n",
    "  legend(\"topleft\",c(\"observational\",\"interventional\"),pch=c(16,17),col=c(blue,red),inset=0.02)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GfZKCL7zJve"
   },
   "source": [
    "Which of the sets are invariant? (There are two plots with four scatter plots each.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0sgjfRSzWEt"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO7tZSjLzMr0",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "What is your best guess for $\\mathrm{pa}(Y)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6QtA9p9zdD7"
   },
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU-jIHvX1rRU",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d) \n",
    "**(optional, and R only)**\n",
    "\n",
    "Use the function ICP to check your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc1nr0TgpNrb"
   },
   "outputs": [],
   "source": [
    "# set up â€“ not needed when run on mybinder\n",
    "# if needed (colab), change FALSE to TRUE and run cell\n",
    "if (FALSE) {\n",
    "  install.packages('InvariantCausalPrediction')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGiVa_SDXTPc"
   },
   "outputs": [],
   "source": [
    "library(InvariantCausalPrediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Confounding and selection bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data\n",
    "\n",
    "We start by generating data from the following SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data <- function(seed){\n",
    "    set.seed(seed)\n",
    "    n <- 200\n",
    "    V <- rbinom(n, 1, 0.2)\n",
    "    W <- 3*V + rnorm(n)\n",
    "    X <- V + rnorm(n)\n",
    "    Y <- X + W^2 + 1 + rnorm(n)\n",
    "    Z <- X + Y + rnorm(n)\n",
    "    data.obs <- data.frame(V=V, W=W, X=X, Y=Y, Z=Z)\n",
    "    return(data.obs)\n",
    "}\n",
    "\n",
    "data.obs <- generate_data(1)\n",
    "\n",
    "# Visualize data set\n",
    "pairs(data.obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume now that we know the causal ordering induced by the SCM and that\n",
    "* $X$ is a treatment variable,\n",
    "* $Y$ is the response and\n",
    "* $(V, W, Z)$ are additional covariates.\n",
    "\n",
    "Furthermore we will assume a partially linear outcome model, i.e., \n",
    "$$Y = \\theta X + g(V, W) + \\epsilon\\quad \\text{with}\\quad\\mathbb{E}[\\epsilon\\mid X, V, W]=0.$$\n",
    "\n",
    "We are interested in estimating the causal effect of $X$ on $Y$, corresponding to the parameter $\\theta$ in the partially linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Background: Confounding and selection bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignoring the causal structure can lead to wrong conclusions. In the following exercise, we will see the two most important types of bias that may occur:\n",
    "* **Confounding bias:** Bias arising because of unaccounted variables that have an effect on both treatment and response.\n",
    "* **Selection bias:** Bias arising due to conditioning on descendents of the response. This can occur either if we only observe a subset of the entire sample or if we mistakenly include a descendent of the response in the outcome model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "\n",
    "In the code below we fitted several different outcome models. Compare the resulting coefficients for $X$. Which regressions appear to lead to unbiased estimates of the causal effect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gam)\n",
    "\n",
    "# linear model of Y on X\n",
    "lin_YX <- lm(Y ~ X, data=data.obs)\n",
    "# linear model of Y on X and V\n",
    "lin_YV <- lm(Y ~ X + V, data=data.obs)\n",
    "# linear model Y on X and W\n",
    "lin_YW <- lm(Y ~ X + W, data=data.obs)\n",
    "# gam model of Y on X and s(W)\n",
    "gam_YW <- gam(Y ~ X + s(W), data=data.obs)\n",
    "# gam model of Y on X, V and s(W)\n",
    "gam_YVW <- gam(Y ~ X + V + s(W), data=data.obs)\n",
    "# gam model of Y on X, V, s(W), s(Z)\n",
    "gam_YVWZ <- lm(Y ~ X + V + W + Z, data=data.obs)\n",
    "\n",
    "# Print each model\n",
    "results = list(linear_X = unname(coefficients(lin_YX)['X']),\n",
    "               linear_V = unname(coefficients(lin_YV)['X']),\n",
    "               linear_W = unname(coefficients(lin_YW)['X']),\n",
    "               gam_W = unname(coefficients(gam_YW)['X']),\n",
    "               gam_VW = unname(coefficients(gam_YVW)['X']),\n",
    "               gam_VWZ = unname(coefficients(gam_YVWZ)['X']))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click (or enter) to edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "List all valid adjustment sets for this causal structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The valid adjustment sets are: $(X, V)$, $(X, W)$ and $(X, V, W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "Assume now that you only have access to the subset $\\texttt{data.cond}$ constructed in the code snippet below. Use a gam regression Y ~ X + s(W) to estimate the causal effect. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cond = data.obs[data.obs$Z<1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit outcome model\n",
    "gam_YW <- gam(Y ~ X + s(W), data=data.cond)\n",
    "print(unname(coefficients(gam_YW)['X']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data set $\\texttt{data.cond}$ was constructed by conditioning on the variable $Z$, which is a a descendent of the response, the causal effect estimate has a selection bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Estimating causal effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same data $\\texttt{data.obs}$ as in Exercise 6 and make the same assumptions. In this exercise you will go over the following approaches for estimating the causal effect from $X$ to $Y$:\n",
    "* **Covariate adjustment:** Directly estimate the outcome model based on a valid adjustment set and use it estimate the causal effect.\n",
    "* **Propensity score matching:** Estimate the propensity score, use it to match samples and then estimate the causal effect based on the matched data.\n",
    "* **Inverse probability weighting:** Estimate the propensity score, use it to weight the samples and then estimate the causal effect based on the weighted sample.\n",
    "* **Double machine learning:** Estimate a regression function for both the propensity model and the outcome model and combine them to estimate the causal effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (a)\n",
    "In this part of the exercise, we will compute a covariate adjustment estimator using the library $\\texttt{gam}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a function $\\texttt{causal\\_effect\\_adjustment}$ that the data $\\texttt{data.obs}$ as input and computes the covariate adjustment estimator with the gam equation Y ~ X + s(W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gam)\n",
    "\n",
    "# Function to estimate causal effect based on covariate adjustment\n",
    "causal_effect_adjustment <- function(data){\n",
    "    gamfit <- gam(Y ~ X + s(W), data = data)\n",
    "    return(unname(coefficients(gamfit)['X']))\n",
    "}\n",
    "\n",
    "# Estimate causal effect\n",
    "ate_adjustment <- causal_effect_adjustment(data.obs)\n",
    "ate_adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (b)\n",
    "In this part of the exercise, we will compute a propensity matching estimator using the library $\\texttt{Matchit}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most matching methods apply only to binary treatments, we first discretize the treatment $X$, compute a binary treatment effect and then backtransform with an adjustment factor. The following code snippet explains this (you can later copy this to your propensity score estimation function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MatchIt)\n",
    "\n",
    "# Create binary treatment (more complicated matching procedures also exist of continuous responses)\n",
    "data.matching <- data.obs\n",
    "T <- as.numeric(data.obs$X > median(data.obs$X))\n",
    "upperT <- mean(data.obs$X[T == 1])\n",
    "lowerT <- mean(data.obs$X[T == 0])\n",
    "adjust_factor <- upperT-lowerT\n",
    "data.matching$T <- T\n",
    "print(adjust_factor)\n",
    "\n",
    "# Without confounding the following estimator would be unbiased\n",
    "lmfit <- lm(Y ~ T, data = data.matching)\n",
    "coefficients(lmfit)['T']/adjust_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the $\\texttt{MatchIt}$ package. First, we need to select an appropriate matching procedure. Consider the following two options, which is preferable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matching object without matching to check if confounding exists\n",
    "match0 <- matchit(T ~ V, data = data.matching,\n",
    "                  method = NULL, distance = \"glm\")\n",
    "summary(match0)\n",
    "plot(match0, type=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching Option 1: Using nearest neighbour matching\n",
    "match1 <- matchit(T ~ V, data = data.matching,\n",
    "                  method = \"nearest\", distance = \"glm\")\n",
    "summary(match1)\n",
    "plot(match1, type=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching Option 2: Using cem matching\n",
    "match2 <- matchit(T ~ V, data = data.matching,\n",
    "                  method = \"cem\", distance = \"glm\")\n",
    "summary(match2)\n",
    "plot(match2, type=\"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the selected matching procedure to implement a function $\\texttt{causal\\_effect\\_matching}$ that takes the data $\\texttt{data.obs}$ as input and computes the propensity score matching estimator of the causal effect of $X$ on $Y$.\n",
    "\n",
    "*Hint: Use the code at the beginning of the question as the first part of your function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate causal effect based on covariate adjustment\n",
    "causal_effect_matching <- function(data){\n",
    "    # Discretize\n",
    "    data.matching <- data\n",
    "    T <- as.numeric(data$X > median(data$X))\n",
    "    upperT <- mean(data$X[T == 1])\n",
    "    lowerT <- mean(data$X[T == 0])\n",
    "    adjust_factor <- upperT-lowerT\n",
    "    data.matching$T <- T\n",
    "    # Apply matching\n",
    "    match2 <- matchit(T ~ V, data = data.matching,\n",
    "                      method = \"cem\", distance = \"glm\")\n",
    "    data.matched <- match.data(match2)\n",
    "    # Compute causal effect\n",
    "    fit_matched <- lm(Y ~ T, data = data.matched, weights=weights)\n",
    "    return(unname(coefficients(fit_matched)['T'])/adjust_factor)\n",
    "}\n",
    "\n",
    "# Estimate causal effect\n",
    "ate_matching <- causal_effect_matching(data.obs)\n",
    "ate_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (c)\n",
    "In this part of the exercise, we will compute an inverse probability weighting estimator using the library $\\texttt{WeightIt}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(WeightIt)\n",
    "\n",
    "# Fit a weightit object based on the covariates (V, W)\n",
    "weight_obj <- weightit(X ~ V + W, data = data.obs, estimand = \"ATE\", method = \"glm\")\n",
    "weight_obj\n",
    "summary(weight_obj)\n",
    "\n",
    "# Plot a histogram of the weights\n",
    "hist(weight_obj$weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code block above to implement a function $\\texttt{causal\\_effect\\_weighting}$ that the data $\\texttt{data.obs}$ as input and computes the inverse probablity weighting estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate causal effect based on inverse probability weighting\n",
    "causal_effect_weighting <- function(data){\n",
    "    weight_obj <- weightit(X ~ V + W, data = data, estimand = \"ATE\", method = \"glm\")\n",
    "    fit_weighted <- lm(Y ~ X, data = data, weights=weight_obj$weights)\n",
    "    return(unname(coefficients(fit_weighted)['X']))\n",
    "}\n",
    "\n",
    "# Estimate causal effect\n",
    "ate_weighting <- causal_effect_weighting(data.obs)\n",
    "ate_weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (d) \n",
    "In this part of the exercise, we will compute a double machine learning estimator using the library $\\texttt{DoubleML}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go over the following code and try to understand the individual steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages (mlr3 packages are required to specify the ML learners)\n",
    "library(DoubleML)\n",
    "library(mlr3)\n",
    "library(mlr3learners)\n",
    "# Suppress output of mlr3 learners during estimation\n",
    "lgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n",
    "\n",
    "\n",
    "# Function to estimate causal effect based on double machine learning\n",
    "causal_effect_dml <- function(data){\n",
    "    # Remove Z as all variables in data will be treated as valid adjustments by DoubleML package\n",
    "    data$Z <- NULL\n",
    "\n",
    "    # Step 1:\n",
    "    # Format the data (this object encodes the causal structure)\n",
    "    obj_dml_data = DoubleMLData$new(data, y_col = \"Y\", d_cols = \"X\")\n",
    "\n",
    "    # Step 2:\n",
    "    # Learner for Y given covariates (V, W) - using random forest from ranger (other learners are possible)\n",
    "    ml_l = lrn(\"regr.ranger\", num.trees = 100, mtry = 2, min.node.size = 2, max.depth = 5)\n",
    "    # Learner for X given covariates (V, W) - using random forest from ranger (other learners are possible)\n",
    "    ml_m = lrn(\"regr.ranger\", num.trees = 100, mtry = 2, min.node.size = 2, max.depth = 5)\n",
    "\n",
    "    # Step 3:\n",
    "    # Setup DML task\n",
    "    doubleml_plr = DoubleMLPLR$new(obj_dml_data,\n",
    "                                   ml_l, ml_m,\n",
    "                                   n_folds = 2,\n",
    "                                   score = \"partialling out\")\n",
    "\n",
    "    # Fit DML\n",
    "    doubleml_plr$fit()\n",
    "    # you can also look at: doubleml_plr$summary()\n",
    "\n",
    "    return(unname(doubleml_plr$all_coef[1]))\n",
    "}\n",
    "\n",
    "# Estimate causal effect\n",
    "ate_weighting <- causal_effect_dml(data.obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### (e)\n",
    "In this part of the exercise, we will compare all estimators using a simulation study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulations\n",
    "B <- 10\n",
    "estimates <- data.frame(adjustment=rep(NA, B),\n",
    "                        matching=rep(NA, B),\n",
    "                        weighting=rep(NA, B),\n",
    "                        dml=rep(NA, B))\n",
    "for(k in 1:B){\n",
    "    data.resample <- generate_data(k)\n",
    "    estimates$adjustment[k] <- causal_effect_adjustment(data.resample)\n",
    "    estimates$matching[k] <- causal_effect_matching(data.resample)\n",
    "    estimates$weighting[k] <- causal_effect_weighting(data.resample)\n",
    "    estimates$dml[k] <- causal_effect_dml(data.resample)\n",
    "}\n",
    "\n",
    "print(estimates)\n",
    "boxplot(estimates)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Causality Tutorial Exercises â€“ R",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
