{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Causality Tutorial Exercises â€“ Python",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3In88vKrq4WB"
      },
      "source": [
        "# Causality Tutorial Exercises â€“ Python\n",
        "\n",
        "Contributors: Rune Christiansen, Jonas Peters, Niklas Pfister, Sorawit Saengkyongam, Sebastian Weichwald.\n",
        "The MIT License applies; copyright is with the authors.\n",
        "Some exercises are adapted from \"Elements of Causal Inference: Foundations and Learning Algorithms\" by J. Peters, D. Janzing and B. SchÃ¶lkopf.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnsIE8yWlVIQ"
      },
      "source": [
        "# Exercise 1 â€“ Structural Causal Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSNemB3GrBIE"
      },
      "source": [
        "\n",
        "Let's first draw a sample from an SCM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cy58Ut1liKd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# set seed\n",
        "np.random.seed(1)\n",
        "\n",
        "rnorm = lambda n: np.random.normal(size=n)\n",
        "\n",
        "n = 200\n",
        "C = rnorm(n)\n",
        "A = .8 * rnorm(n)\n",
        "K = A + .1 * rnorm(n)\n",
        "X = C - 2 * A + .2 * rnorm(n)\n",
        "F = 3 * X + .8 * rnorm(n)\n",
        "D = -2 * X + .5 * rnorm(n)\n",
        "G = D + .5 * rnorm(n)\n",
        "Y = 2 * K - D + .2 * rnorm(n)\n",
        "H = .5 * Y + .1 * rnorm(n)\n",
        "\n",
        "data = np.c_[C, A, K, X, F, D, G, Y, H]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PMvvEeIoKFN"
      },
      "source": [
        "__a)__\n",
        "\n",
        "What is the graph corresponding to the above SCM? (Draw on a paper.)\n",
        "\n",
        "Take a pair of variables and think about whether you expect this pair to be dependent\n",
        "(at this stage, you can only guess, later you will have tools to know). Check empirically.\n",
        "\n",
        "__b)__\n",
        "\n",
        "Generate a sample of size 300 from the interventional distribution $P_{\\mathrm{do}(X=\\mathcal{N}(2, 1))}$\n",
        "and store the data matrix as `data_int`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtbA6c2Ron5f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wOg_4vozpz"
      },
      "source": [
        "__c)__\n",
        "\n",
        "Do you expect the marginal distribution of $Y$ to be different in both samples?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3paV1bkro6lV"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH9Tt444o-RH"
      },
      "source": [
        "__d)__\n",
        "\n",
        "Do you expect the joint distribution of $(A, Y)$ to be different in both samples?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJz4fZKEpE4-"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZmh_AizpGp-"
      },
      "source": [
        "__e)__\n",
        "\n",
        "Check your answers to c) and d) empirically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2PMSXqKpLpH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Idk_ElwrEht"
      },
      "source": [
        "# Exercise 2 â€“ Adjusting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il0b9fnVq-bz"
      },
      "source": [
        "\n",
        "![DAG](https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.png)\n",
        "\n",
        "Suppose we are given a fixed DAG (like the one above).\n",
        "\n",
        "a) What are valid adjustment sets (VAS) used for?\n",
        "\n",
        "b) Assume we want to find a VAS for the causal effect from $X$ to $Y$.\n",
        "What are general recipies (plural ðŸ˜‰) for constructing VASs (no proof)?\n",
        "Which sets are VAS in the DAG above?\n",
        "\n",
        "c) The following code samples from an SCM. Perform linear regressions using different VAS and compare the regression coefficient against the causal effect from $X$ to $Y$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3y5ckYKJHiJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# set seed\n",
        "np.random.seed(1)\n",
        "\n",
        "rnorm = lambda n: np.random.normal(size=n)\n",
        "\n",
        "n = 200\n",
        "C = rnorm(n)\n",
        "A = .8 * rnorm(n)\n",
        "K = A + .1 * rnorm(n)\n",
        "X = C - 2 * A + .2 * rnorm(n)\n",
        "F = 3 * X + .8 * rnorm(n)\n",
        "D = -2 * X + .5 * rnorm(n)\n",
        "G = D + .5 * rnorm(n)\n",
        "Y = 2 * K - D + .2 * rnorm(n)\n",
        "H = .5 * Y + .1 * rnorm(n)\n",
        "\n",
        "data = np.c_[C, A, K, X, F, D, G, Y, H]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqFFtwP5JQVw"
      },
      "source": [
        "d) Why could it be interesting to have several options for choosing a VAS?\n",
        "\n",
        "e) If you indeed have access to several VASs, what would you do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ7RuuF4rMD6"
      },
      "source": [
        "# Exercise 3 â€“ Independence-based Causal Structure Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p21N9AFBrB0o"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Assume $P^{X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
        "\n",
        "$$\n",
        "\\newcommand{\\indep}{{\\,â««\\,}}\n",
        "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
        "$$\n",
        "\n",
        "$$X \\dep Z \\mid \\emptyset$$\n",
        "\n",
        "(plus symmetric statements). What is $G$?\n",
        "\n",
        "__b)__\n",
        "\n",
        "Assume $P^{W,X,Y,Z}$ is Markov and faithful wrt. $G$. Assume all (!) conditional independences are\n",
        "\n",
        "$$\\begin{aligned}\n",
        "(Y,Z) &\\indep W \\mid \\emptyset \\\\\n",
        "W &\\indep Y \\mid (X,Z) \\\\\n",
        "(X,W) &\\indep Y | Z\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "(plus symmetric statements). What is $G$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "craCADN8rKd3"
      },
      "source": [
        "# Exercise 4 â€“ Additive Noise Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlFh1Zk50_z7"
      },
      "source": [
        "Set-up required packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk3IE7jvvUxG"
      },
      "source": [
        "# set up â€“ not needed when run on mybinder\n",
        "# if needed (colab), change False to True and run cell\n",
        "if False:\n",
        "  !mkdir ../data/\n",
        "  !wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ANM.csv -q -O ../data/Exercise-ANM.csv\n",
        "  !wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/python/kerpy/__init__.py -q -O kerpy.py\n",
        "  !pip install pygam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNsEcFUJ1P4I"
      },
      "source": [
        "from kerpy import hsic\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pygam import GAM, s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmh91goS1DCT"
      },
      "source": [
        "Let's load and plot some real data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hwvlkYX1EPW"
      },
      "source": [
        "data = pd.read_csv('../data/Exercise-ANM.csv')\n",
        "\n",
        "plt.scatter(data[\"X\"].values, data[\"Y\"].values, s=2.);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uDnv5eD2pGd"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Do you believed that $X \\to Y$ or that $X \\gets Y$? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4owvM1J_2rcM"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYdffpZN2uDc"
      },
      "source": [
        "$$\n",
        "\\newcommand{\\indep}{{\\,â««\\,}}\n",
        "\\newcommand{\\dep}{\\not{}\\!\\!\\indep}\n",
        "$$\n",
        "\n",
        "__b)__\n",
        "Let us now try to get a more statistical answer. We have heard that we cannot \n",
        "have  \n",
        "$$Y = f(X) + N_Y,\\ N_Y \\indep X$$\n",
        "and\n",
        "$$X = g(Y) + N_X,\\ N_X \\indep Y$$\n",
        "at the same time.\n",
        "\n",
        "Given a data set over $(X,Y)$,\n",
        "we now want to decide for one of the two models. \n",
        "\n",
        "Come up with a method to do so.\n",
        "\n",
        "Hints: \n",
        "* `GAM(s(0)).fit(A, B).deviance_residuals(A, B)` provides residuals when regressing $B$ on $A$.\n",
        "* `hsic(a, b)` can be used as an independence test (here, `a` and `b` are $n \\times 1$ numpy arrays)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llz5Eeck2xz5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8SBfEFi6oqH"
      },
      "source": [
        "__c)__\n",
        "\n",
        "Assume that the error terms are Gaussian with zero mean and variances \n",
        "$\\sigma_X^2$ and $\\sigma_Y^2$, respectively.\n",
        "The maximum likelihood for DAG G is \n",
        "then proportional to \n",
        "$-\\log(\\mathrm{var}(R^G_X)) - \\log(\\mathrm{var}(R^G_Y))$,\n",
        "where $R^G_X$ and $R^G_Y$ are the residuals obtained from regressing $X$ and $Y$ on \n",
        "their parents in $G$, respectively (no proof).\n",
        "\n",
        "Find the maximum likelihood solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pASFG1DC6sQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JPYnSHrOfW"
      },
      "source": [
        "# Exercise 5 â€“ Invariant Causal Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb5CwEUEAaOp"
      },
      "source": [
        "Set-up required packages and data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wudBwtYswFeo"
      },
      "source": [
        "# set up â€“ not needed when run on mybinder\n",
        "# if needed (colab), change False to True and run cell\n",
        "if False:\n",
        "  !mkdir ../data/\n",
        "  !wget https://raw.githubusercontent.com/sweichwald/causality-tutorial-exercises/main/data/Exercise-ICP.csv -q -O ../data/Exercise-ICP.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIosbymbbkhg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy8eUIaDdmrz"
      },
      "source": [
        "__a)__\n",
        "\n",
        "Generate some observational and interventional data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGBQGfetbYPj"
      },
      "source": [
        "# Generate n=1000 observations from the observational distribution\n",
        "na = 1000\n",
        "Xa = np.random.normal(size=na)\n",
        "Ya = 1.5*Xa + np.random.normal(size=na)\n",
        "\n",
        "# Generate n=1000 observations from an interventional distribution\n",
        "nb = 1000\n",
        "Xb = np.random.normal(loc=2, scale=1, size=nb)\n",
        "Yb = 1.5*Xb + np.random.normal(size=nb)\n",
        "\n",
        "# plot Y vs X1\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.scatter(Xa, Ya, label='observational', marker='o', alpha=0.6)\n",
        "ax.scatter(Xb, Yb, label='interventional', marker ='^', alpha=0.6)\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcSibWjypDR"
      },
      "source": [
        "Look at the above plot. Is the predictor $\\{X\\}$ an invariant set, that is (roughly speaking), does $Y \\mid X = x$ have the same distribution in the orange and blue data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhnmzEIiyvmt"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnDdgV_QeEFH"
      },
      "source": [
        "__b)__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqcN5gRdeRoi"
      },
      "source": [
        "We now consider data over a response and three covariates $X1, X2$, and $X3$\n",
        "and try to infer $\\mathrm{pa}(Y)$. To do so, we need to find all sets for which this\n",
        "invariance is satisfied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4vMv59_wjKG"
      },
      "source": [
        "# load data\n",
        "data = pd.read_csv('../data/Exercise-ICP.csv')\n",
        "data['env'] = np.concatenate([np.repeat('observational', 140), np.repeat('interventional', 80)])\n",
        "# pairplot\n",
        "sns.pairplot(data, hue='env', height=2, plot_kws={'alpha':0.6});"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yF7KhYZe7g9"
      },
      "source": [
        "# The code below plots the residuals versus fitted values for all sets of \n",
        "# predictors. \n",
        "# extract response and predictors\n",
        "\n",
        "Y = data['Y'].to_numpy()\n",
        "X = data[['X1','X2','X3']].to_numpy()\n",
        "# get environment indicator\n",
        "obs_ind = data[data['env'] == 'observational'].index\n",
        "int_ind = data[data['env'] == 'interventional'].index\n",
        "# create all sets\n",
        "all_sets = [(0,), (1,), (2,), (0,1), (0,2), (1,2), (0,1,2)]\n",
        "# label each set\n",
        "set_labels = ['X1', 'X2', 'X3', 'X1,X2', 'X1,X3', 'X2,X3', 'X1,X2,X3']\n",
        "\n",
        "# fit OLS and store fitted values and residuals for each set\n",
        "fitted = []\n",
        "resid = []\n",
        "for s in all_sets:\n",
        "  model = sm.OLS(Y, X[:, s]).fit()\n",
        "  fitted += [model.fittedvalues]\n",
        "  resid += [model.resid]\n",
        "\n",
        "# plotting function\n",
        "def plot_fitted_resid(fv, res, ax, title):\n",
        "  ax.scatter(fv[obs_ind], res[obs_ind], label='observational', marker='o', alpha=0.6)\n",
        "  ax.scatter(fv[int_ind], res[int_ind], label='interventional', marker ='^', alpha=0.6)\n",
        "  ax.legend()\n",
        "  ax.set_xlabel('fitted values')\n",
        "  ax.set_ylabel('residuals')\n",
        "  ax.set_title(title)\n",
        "\n",
        "# creating plots\n",
        "fig, axes = plt.subplots(4, 2, figsize=(7,14))\n",
        "\n",
        "# plot result for the empty set predictor\n",
        "ax0 = axes[0,0]\n",
        "ax0.scatter(obs_ind, Y[obs_ind], label='observational', marker='o', alpha=0.6)\n",
        "ax0.scatter(int_ind, Y[int_ind], label='interventional', marker ='^', alpha=0.6)\n",
        "ax0.legend()\n",
        "ax0.set_xlabel('index')\n",
        "ax0.set_ylabel('Y')\n",
        "ax0.set_title('empty set')\n",
        "\n",
        "# plot result for the other sets\n",
        "for i, ax in enumerate(axes.flatten()[1:]):\n",
        "  plot_fitted_resid(fitted[i], resid[i], ax, set_labels[i])\n",
        "\n",
        "# make tight layout\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GfZKCL7zJve"
      },
      "source": [
        "Which of the sets are invariant? (There are two plots with four scatter plots each.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0sgjfRSzWEt"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO7tZSjLzMr0"
      },
      "source": [
        "__c)__\n",
        "What is your best guess for $\\mathrm{pa}(Y)$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6QtA9p9zdD7"
      },
      "source": [
        "Double-click (or enter) to edit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZGGVS8lP0Ly"
      },
      "source": [
        "__d) (optional)__\n",
        "\n",
        "Use the function ICP to check your result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qi2_GCnQmEG"
      },
      "source": [
        "# set up â€“ not needed when run on mybinder\n",
        "# if needed (colab), change False to True and run cell\n",
        "if False:\n",
        "  !pip install causalicp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqUzMXw5QLva"
      },
      "source": [
        "import causalicp as icp"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}